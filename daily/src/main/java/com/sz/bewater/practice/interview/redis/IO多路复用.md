redis是单线程的为什么还这么快?
1.首先redis是基于内存的,内存的读写速度快,这是最主要的原因
2.单线程避免的线程上下文的切换
3.redis使用了多路复用的IO模型，使得它能够在单线程中高效地处理大量并发连接。
用户态(空间): 应用程序运行的空间，受限于操作权限，不能直接进行硬件操作，需要通过系统调用与内核态进行交互。
内核态(空间): 操作系统内核运行的空间，具有完全的操作权限，可以直接访问硬件和管理系统资源。
我们应用程序想要做某件事 其实最根本的目的是去操作硬件的  而在用户态下是不能去操作硬件的 必须得依赖于操作系统 也就是系统调用才行  所以必然面临着用户态和内核态的通信  这是IO模型最主要的性能瓶颈
（以下是一个更详细的例子来展示用户态和内核态之间的数据拷贝：
客户端连接服务器：
客户端调用 connect()，将服务器地址和端口信息从用户态拷贝到内核态。
内核生成并发送 TCP SYN 包，通过网络传输到服务器。
服务器接受连接：
服务器调用 accept()，内核处理来自客户端的 SYN 包并返回 SYN-ACK 包给客户端。
内核将新的客户端连接信息拷贝到用户态，并返回新的套接字描述符。
在这些过程中，数据拷贝的关键在于：
将控制信息（如套接字描述符、地址和端口信息）从用户态传递到内核态。
处理网络传输的数据包时在内核态中进行，确保高效的网络通信。）
BIO: 阻塞IO模型  用户进程通过recvfrom这个系统调用 去请求内核中的数据 此时用户进程是阻塞住的 一直等到内核中的数据准备就绪 数据准备就绪 则从内核空间拷贝到用户空间 这一过程也是阻塞的 
NIO:非阻塞IO模型  用户进程通过recvfrom系统调用请求内核 假如说内核空间中数据未准备就绪 则会直接返回一个异常给用户进程  用户进程接受到这个异常后继续发送recvfrom请求  这个过程持续到内核中数据准备就绪  相较于BIO虽然说是非阻塞的 但是性能也不高  用户进程处于一个忙等待 cpu占有率会比较高
IO多路复用: 通过单线程去监听多个socket  当一个或者多个socket可读或者可写就去通知用户进程 充分利用了cpu资源 效率比较高
IO多路复用的三种模式:select、poll、epoll
select：传统的IO多路复用模型  虽然监听了多个socket  但是并不知道具体哪个socket准备就绪  需要轮询遍历  而且有文件描述符的限制 通常是1024
poll：与select相比虽然没有文件描述符的限制 但是仍然不知道具体哪个socket准备就绪 仍需要轮询遍历
epoll：才有事件通知的机制 准确知道哪个socket准备就绪 并将准备就绪的socket拷贝到用户空间  且没有文件描述符的限制
目前redis会根据不同的操作系统 选择最优的IO多路复用模型  可在redis命令行通过info命令查看用到了哪个模型
目前redis6.0虽然引入了多线程  但是核心事件循环和命令执行还是单线程的  多线程是使用在命令的接收和命令的回复上
延伸面试题：redis单线程是怎么处理大量并发连接的（多路复用）